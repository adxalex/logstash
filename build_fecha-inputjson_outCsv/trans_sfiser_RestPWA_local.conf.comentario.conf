input {
   file {
      path => "/mnt/c/adx/Proyectos/logstash/logstash-7.12.0/config/config/trans_sfiser_RestPWA.json"
      #start_position => "beginning"
      #type => "json"
      #codec => json_lines { charset => CP1252 }
      #codec=> "json"
      #tags                        => [ "filejson" ]
  }
}

filter {

##-Empieza--Transacciones_SFISERS611C01_COC-16p-17p-#

# La condicion dice que si el texto entre comillas se encuentra dentro del campo message va a parsear con respecto a lo que esta dentro del if.

if [message] =~ "Transacciones_SFISERS611C01_COC-1016p" {

#el filtro json, para leer el input file que es formato json.

    json { source => "message" remove_field => [ "message" ] }

# A continuacion se agregan los campos (puede ser cualquier nombre) pero la ruta debe indidcar en que nivel esta el dato queremos obtener. puede ayudar "jsonformatter.org"
    mutate {
        add_field => {
            "LASTPOLLEDTIME611C16p" => "%{[response][result][0][LASTPOLLEDTIME]}"
            "DISPLAYNAME611C16p" => "%{[response][result][0][DISPLAYNAME]}"
            "Value611C16p" => "%{[response][result][0][CHILDMONITORS][0][CHILDMONITORINFO][10][CHILDATTRIBUTES][0][Value]}"
            "Valuetime611C16p" => "%{[response][result][0][CHILDMONITORS][0][CHILDMONITORINFO][147][CHILDATTRIBUTES][0][Value]}"

# Se eliminan los campos que no necesitamos ver en la salida.

                      }
          remove_field => [ "response", "path","host","@version","response-code"]
    }

# con grok vamos a buscar un archivo pattern ubicado en la ruta indicada, este archivo tiene patrones personalizados para poder leer los campos indicados, formatearlos y renomnrarlos.

    grok {
        patterns_dir => ["/mnt/c/adx/Proyectos/logstash/logstash-7.12.0/config/config/pattern"]
        match => {
                  "Valuetime611C16p" => "%{horamin:rest}"
                  }
          }

    grok {
        patterns_dir => ["/mnt/c/adx/Proyectos/logstash/logstash-7.12.0/config/config/pattern"]
        match => {
                  "LASTPOLLEDTIME611C16p" => "%{anomesdia}"
                  }
          }

#-----Formato valido para el zoho "18-Oct-2022 19:49"----#
# con add_field en este caso combinamos varios campos que hemos generado con las lineas anteriores y los unimos en un solo campo.

    mutate{
      add_field => {
                  "SFISERTIME611C16p" => "%{dia}-%{mes}-%{ano} %{hora}:%{min}"
                  }
          }
# gsub es para que cuando encuentre la palabra ene la cambie por jan, esto es debido a que APM nos da el mes en espaÃ±ol y zoho las espera en ingles.
    mutate {
      gsub => ["SFISERTIME611C16p", "ene", "jan"]
      gsub => ["SFISERTIME611C16p", "abr", "apr"]
      gsub => ["SFISERTIME611C16p", "ago", "aug"]
      gsub => ["SFISERTIME611C16p", "dic", "dec"]
      remove_field => ["ano","mes","dia","min","hora","seg","Valuetime611C16p","date","LASTPOLLEDTIME611C16p","@timestamp","rest"]
    }


}

#-Termina--Transacciones_SFISERS611C01_COC-16p-17p-#

}

output {

stdout {
      codec => rubydebug
    }
#------------------------------Output1016p-------------------------------------

# csv {
#  csv_options => {"headers" => true}
#  fields => ["fechapool", "[DISPLAYNAME515C16p]","[Value515C16p]"]
#  path => "/mnt/c/adx/Proyectos/logstash/logstash-7.12.0/config/config/trans_sfiser_RestPWA.csv"
#  }

}